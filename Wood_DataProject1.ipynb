{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8977cdce",
   "metadata": {},
   "source": [
    "# Data Project 1 - Ryan Wood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e130c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements, don't know if I'll need all of them\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import numpy\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import pprint\n",
    "\n",
    "import pymongo\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a32cf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "host_name = \"localhost\"\n",
    "host_ip = \"127.0.0.1\"\n",
    "port = \"3306\"\n",
    "user_id = \"root2\"\n",
    "pwd = \"123456789\"\n",
    "\n",
    "src_dbname = \"dp1updated\"\n",
    "dst_dbname = \"dp1mongoupdates\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b6cc90",
   "metadata": {},
   "source": [
    "### Define Functions for Getting Data From and Setting Data Into Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d460c8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(user_id, pwd, host_name, db_name, sql_query):\n",
    "    conn_str = f\"mysql+pymysql://{user_id}:{pwd}@{host_name}/{db_name}\"\n",
    "    sqlEngine = create_engine(conn_str, pool_recycle=3600)\n",
    "    connection = sqlEngine.connect()\n",
    "    dframe = pd.read_sql(sql_query, connection);\n",
    "    connection.close()\n",
    "    \n",
    "    return dframe\n",
    "\n",
    "\n",
    "def set_dataframe(user_id, pwd, host_name, db_name, df, table_name, pk_column, db_operation):\n",
    "    conn_str = f\"mysql+pymysql://{user_id}:{pwd}@{host_name}/{db_name}\"\n",
    "    sqlEngine = create_engine(conn_str, pool_recycle=3600)\n",
    "    connection = sqlEngine.connect()\n",
    "    \n",
    "    if db_operation == \"insert\":\n",
    "        df.to_sql(table_name, con=connection, index=False, if_exists='replace')\n",
    "        sqlEngine.execute(f\"ALTER TABLE {table_name} ADD PRIMARY KEY ({pk_column});\")\n",
    "            \n",
    "    elif db_operation == \"update\":\n",
    "        df.to_sql(table_name, con=connection, index=False, if_exists='append')\n",
    "    \n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c289b46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    conn_str = f\"mysql+pymysql://{user_id}:{pwd}@{host_name}\"\n",
    "    sqlEngine = create_engine(conn_str, pool_recycle=3600)\n",
    "\n",
    "    sqlEngine.execute(f\"DROP DATABASE IF EXISTS `{src_dbname}`;\")\n",
    "    sqlEngine.execute(f\"CREATE DATABASE `{src_dbname}`;\")\n",
    "    sqlEngine.execute(f\"USE {src_dbname};\")\n",
    "except:\n",
    "    print(\"There was an error creating a sql engine from the information provided in the program\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ce49ad",
   "metadata": {},
   "source": [
    "### CSV to SQL conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd39165b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data_dir = os.path.join(os.getcwd(), 'data')\n",
    "    data_file = os.path.join(data_dir, 'superbowl.csv')\n",
    "    # df = pd.read_csv(data_file, header=0, index_col=0)\n",
    "    df = pd.read_csv(data_file)\n",
    "    total_rows = len(df.axes[0]) #===> Axes of 0 is for a row\n",
    "    total_cols = len(df.axes[1]) #===> Axes of 1 is for a column\n",
    "    print(\"Number of Rows: \" + str(total_rows))\n",
    "    print(\"Number of Columns: \" + str(total_cols))\n",
    "    df.head()\n",
    "except:\n",
    "    print(\"The file could not be read in correctly.\")\n",
    "    print(\"Make sure the data file is in the correct directory so it can be inserted properly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4c8250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Super Bowl 55\n",
    "new_row = pd.DataFrame({'Date':'Feb 7 2021', 'SB':'LV (55)', 'Winner':'Tampa Bay Buccaneers', 'Winner Pts':'31',\n",
    "                        'Loser':'Kansas City Chiefs', 'Loser Pts':'9', 'MVP':'Tom Brady',\n",
    "                        'Stadium':'Raymond James Stadium', 'City':'Tampa', 'State':'Florida'}, index = [0])\n",
    "df = pd.concat([new_row, df]).reset_index(drop = True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44586e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Super Bowl 56\n",
    "new_row2 = pd.DataFrame({'Date':'Feb 13 2022', 'SB':'LVI (56)', 'Winner':'Los Angeles Rams', 'Winner Pts':'23', \n",
    "                          'Loser':'Cincinnati Bengals', 'Loser Pts':'20','MVP':'Cooper Kupp', 'Stadium':'SoFi Stadium', \n",
    "                            'City':'Inglewood', 'State':'California'}, index = [0])\n",
    "df = pd.concat([new_row2, df]).reset_index(drop = True)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a5ccd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop useless column\n",
    "df.drop('State', axis=1, inplace=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b753dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_val = 1\n",
    "df.insert(loc=0, column = 'surr_key', value = range(start_val, len(df) + start_val))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e393192f",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_dataframe(user_id, pwd, host_name, \"dp1updated\", df, \"superbowls\", \"surr_key\", \"insert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd64582",
   "metadata": {},
   "source": [
    "### Convert from SQL to MongoDB Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe43aff8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# host_name = \"localhost\"\n",
    "ports = {\"mongo\" : 27017, \"mysql\" : 3306}\n",
    "\n",
    "# user_id = \"root2\"\n",
    "# pwd = \"123456789\"\n",
    " \n",
    "src_dbname = \"dp1updated\"\n",
    "dst_dbname = \"dp1mongoupdates\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c345273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sql_dataframe(user_id, pwd, host_name, db_name, sql_query):\n",
    "    '''Create a connection to the MySQL database'''\n",
    "    conn_str = f\"mysql+pymysql://{user_id}:{pwd}@{host_name}/{db_name}\"\n",
    "    sqlEngine = create_engine(conn_str, pool_recycle=3600)\n",
    "    \n",
    "    '''Invoke the pd.read_sql() function to query the database, and fill a Pandas DataFrame.'''\n",
    "    conn = sqlEngine.connect()\n",
    "    dframe = pd.read_sql(sql_query, conn);\n",
    "    conn.close()\n",
    "    \n",
    "    return dframe\n",
    "\n",
    "\n",
    "def get_mongo_dataframe(user_id, pwd, host_name, port, db_name, collection, query):\n",
    "    '''Create a connection to MongoDB, with or without authentication credentials'''\n",
    "    if user_id and pwd:\n",
    "        mongo_uri = 'mongodb://%s:%s@%s:%s/%s' % (username, password, host, port, db_name)\n",
    "        client = pymongo.MongoClient(mongo_uri)\n",
    "    else:\n",
    "        conn_str = f\"mongodb://{host_name}:{port}/\"\n",
    "        client = pymongo.MongoClient(conn_str)\n",
    "    \n",
    "    '''Query MongoDB, and fill a python list with documents to create a DataFrame'''\n",
    "    db = client[db_name]\n",
    "    dframe = pd.DataFrame(list(db[collection].find(query)))\n",
    "    dframe.drop(['_id'], axis=1, inplace=True)\n",
    "    client.close()\n",
    "    \n",
    "    return dframe\n",
    "\n",
    "\n",
    "def set_dataframe(user_id, pwd, host_name, db_name, df, table_name, pk_column, db_operation):\n",
    "    '''Create a connection to the MySQL database'''\n",
    "    conn_str = f\"mysql+pymysql://{user_id}:{pwd}@{host_name}/{db_name}\"\n",
    "    sqlEngine = create_engine(conn_str, pool_recycle=3600)\n",
    "    connection = sqlEngine.connect()\n",
    "    \n",
    "    '''Invoke the Pandas DataFrame .to_sql( ) function to either create, or append to, a table'''\n",
    "    if db_operation == \"insert\":\n",
    "        df.to_sql(table_name, con=connection, index=False, if_exists='replace')\n",
    "        sqlEngine.execute(f\"ALTER TABLE {table_name} ADD PRIMARY KEY ({pk_column});\")\n",
    "            \n",
    "    elif db_operation == \"update\":\n",
    "        df.to_sql(table_name, con=connection, index=False, if_exists='append')\n",
    "    \n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d709279b",
   "metadata": {},
   "source": [
    "#### RUN THIS ONLY ONCE (OR ELSE MONGO WILL HAVE DUPLICATE ENTRIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9087fa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only run this when you are going back through the project again after running the cell below once\n",
    "port = ports[\"mongo\"]\n",
    "conn_str = f\"mongodb://{host_name}:{port}/\"\n",
    "client = pymongo.MongoClient(conn_str)\n",
    "db = client[src_dbname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2223cf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE FOR MYSELF: DO NOT RUN ANY MORE, ALREADY IN MONGO\n",
    "\n",
    "port = ports[\"mongo\"]\n",
    "conn_str = f\"mongodb://{host_name}:{port}/\"\n",
    "client = pymongo.MongoClient(conn_str)\n",
    "db = client[src_dbname]\n",
    "\n",
    "data_dir = os.path.join(os.getcwd(), 'data')\n",
    "\n",
    "json_files = {\"SBstats\" : 'superbowl_json.json'\n",
    "             }\n",
    "\n",
    "for file in json_files:\n",
    "    json_file = os.path.join(data_dir, json_files[file])\n",
    "    with open(json_file, 'r') as openfile:\n",
    "        json_object = json.load(openfile)\n",
    "        file = db[file]\n",
    "        result = file.insert_many(json_object)\n",
    "        #print(f\"{file} was successfully loaded.\")\n",
    "\n",
    "        \n",
    "# client.close()     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14662df",
   "metadata": {},
   "source": [
    "#### Transformations within MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cac99ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = {}\n",
    "port = ports[\"mongo\"]\n",
    "collection = \"SBstats\"\n",
    "\n",
    "df_mongo_orig = get_mongo_dataframe(None, None, host_name, port, src_dbname, collection, query)\n",
    "df_mongo_orig.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7803af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sql_cowboys = \"SELECT * FROM dp1updated.superbowls WHERE `Winner` = 'Dallas Cowboys';\"\n",
    "df_cowboys_sb = get_sql_dataframe(user_id, pwd, host_name, src_dbname, sql_cowboys)\n",
    "df_cowboys_sb.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697747de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "db.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82efbeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = \"SBstats\"\n",
    "\n",
    "stats = db[collection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7861458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The SELECT list -----------------------------------------------\n",
    "projection = {\"_id\": 0, \"Date\": 1, \"SB\": 1, \"Winner\": 1, \"Winner Pts\": 1, \"Loser\": 1, \"Loser Pts\": 1, \"MVP\": 1,\n",
    "             \"Stadium\": 1, \"City\": 1, \"State\": 1}\n",
    "\n",
    "# The WHERE clause ----------------------------------------------\n",
    "conditions = {\"Winner\":{\"$eq\": \"Dallas Cowboys\"}}\n",
    "\n",
    "# The ORDER BY clause -------------------------------------------\n",
    "orderby = [(\"Date\", -1)]\n",
    "\n",
    "for title in stats.find(conditions, projection).sort(orderby):\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d868575",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cowboys_sb_mongo = pd.DataFrame( list( stats.find(conditions, projection).sort(orderby) ) )\n",
    "df_cowboys_sb_mongo.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1f615a",
   "metadata": {},
   "source": [
    "#### Do more things in MongoDB before pushing back to new SQL Schema from Modified SQL Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53ab882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE FOR MYSELF: DO NOT RUN ANY MORE, ALREADY IN MONGO\n",
    "\n",
    "port = ports[\"mongo\"]\n",
    "conn_str = f\"mongodb://{host_name}:{port}/\"\n",
    "client = pymongo.MongoClient(conn_str)\n",
    "db2 = client[dst_dbname]\n",
    "\n",
    "data_dir = os.path.join(os.getcwd(), 'data')\n",
    "\n",
    "json_files = {\"updated_sb_stats\" : 'updated_superbowls_as_json.json'\n",
    "             }\n",
    "\n",
    "for file in json_files:\n",
    "    json_file = os.path.join(data_dir, json_files[file])\n",
    "    with open(json_file, 'r') as openfile:\n",
    "        json_object = json.load(openfile)\n",
    "        file = db2[file]\n",
    "        result = file.insert_many(json_object)\n",
    "        print(f\"{file} was successfully loaded.\")\n",
    "\n",
    "        \n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59662de",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {}\n",
    "port = ports[\"mongo\"]\n",
    "collection = \"updated_sb_stats\"\n",
    "\n",
    "conn_str = f\"mongodb://{host_name}:{port}/\"\n",
    "client = pymongo.MongoClient(conn_str)\n",
    "db2 = client[dst_dbname]\n",
    "\n",
    "try:\n",
    "    df_mongo_updated = get_mongo_dataframe(None, None, host_name, port, dst_dbname, collection, query)\n",
    "    df_mongo_updated.head(5)\n",
    "except:\n",
    "    print(\"There was an error getting the MongoDB dataframe.\")\n",
    "    print(\"Make sure the dataframe exists and other arguments are correct.\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de101890",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_cowboys2 = \"SELECT * FROM dp1updated.superbowls WHERE `Winner` = 'Dallas Cowboys';\"\n",
    "df_cowboys_sb2 = get_sql_dataframe(user_id, pwd, host_name, src_dbname, sql_cowboys2)\n",
    "df_cowboys_sb2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0f0d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "db2.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829f1f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection2 = \"updated_sb_stats\"\n",
    "\n",
    "stats2 = db2[collection2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c001f042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The SELECT list -----------------------------------------------\n",
    "projection2 = {\"_id\": 0, \"surr_key\": 1, \"Date\": 1, \"SB\": 1, \"Winner\": 1, \"Winner Pts\": 1, \"Loser\": 1,\n",
    "               \"Loser Pts\": 1, \"MVP\": 1, \"Stadium\": 1, \"City\": 1}\n",
    "\n",
    "# The WHERE clause ----------------------------------------------\n",
    "conditions = {\"Winner\":{\"$eq\": \"Dallas Cowboys\"}}\n",
    "\n",
    "# The ORDER BY clause -------------------------------------------\n",
    "orderby = [(\"Date\", 1)]\n",
    "\n",
    "for title in stats2.find(conditions, projection2).sort(orderby):\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c601c57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cowboys_sb_mongo_updated = pd.DataFrame( list( stats2.find(conditions, projection2).sort(orderby) ) )\n",
    "df_cowboys_sb_mongo_updated.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b5fde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert into sql schema again\n",
    "\n",
    "dataframe = df_cowboys_sb_mongo_updated\n",
    "table_name = 'updated_sb_stats'\n",
    "primary_key = 'surr_key'\n",
    "db_operation = \"insert\"\n",
    "\n",
    "try:\n",
    "    set_dataframe(user_id, pwd, host_name, src_dbname, dataframe, table_name, primary_key, db_operation)\n",
    "except:\n",
    "    print(\"There was an error setting the new dataframe.\")\n",
    "    print(\"Make sure the destination database, primary key, and other arguments are correct.\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb46fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
